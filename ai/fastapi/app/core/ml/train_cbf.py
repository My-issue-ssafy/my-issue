# Content-Based Filtering (CBF) ì¶”ì²œ ëª¨ë¸ í•™ìŠµ ëª¨ë“ˆ
# ì‚¬ìš©ì ìƒí˜¸ì‘ìš© ë°ì´í„°ì™€ ë‰´ìŠ¤ ì„ë² ë”©ì„ í™œìš©í•œ ì½˜í…ì¸  ê¸°ë°˜ ì¶”ì²œ ì‹œìŠ¤í…œ

import os
import pickle
import json
import numpy as np
import pandas as pd
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import normalize

from app.config import PROJECT_ID, DEFAULT_DATASET, LOOKBACK_DAYS
from app.core.analytics.bq import get_client, get_latest_date
from app.core.ml.train_cf import fetch_interactions, today_kst_str, already_trained_today as cf_already_trained_today
from app.db.models.news import News
from app.utils.config import settings

# ëª¨ë¸ ì €ì¥ ê²½ë¡œ ì„¤ì •
MODELS_DIR = Path(__file__).resolve().parent.parent.parent / "models"
CBF_MODEL_PATH = MODELS_DIR / "cbf_model.pkl"
CBF_METADATA_PATH = MODELS_DIR / "cbf_metadata.json"

# ë§ˆì§€ë§‰ CBF í•™ìŠµ ë‚ ì§œë¥¼ ê¸°ë¡í•˜ëŠ” íŒŒì¼ ê²½ë¡œ
CBF_STATE_PATH = os.path.join(os.path.dirname(__file__), "..", "..", "..", "cbf_last_trained.txt")

# ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„¤ì •
engine = create_engine(settings.DATABASE_URL, pool_pre_ping=True)
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

def already_trained_cbf_today() -> bool:
    """ì˜¤ëŠ˜ ì´ë¯¸ CBF ëª¨ë¸ í•™ìŠµì„ ì™„ë£Œí–ˆëŠ”ì§€ í™•ì¸"""
    if not os.path.exists(CBF_STATE_PATH):
        return False
    with open(CBF_STATE_PATH, "r", encoding="utf-8") as f:
        last = f.read().strip()
    return last == today_kst_str()

def mark_cbf_trained_today():
    """ì˜¤ëŠ˜ CBF ëª¨ë¸ í•™ìŠµì„ ì™„ë£Œí–ˆë‹¤ëŠ” í‘œì‹œë¥¼ íŒŒì¼ì— ê¸°ë¡"""
    os.makedirs(os.path.dirname(CBF_STATE_PATH), exist_ok=True)
    with open(CBF_STATE_PATH, "w", encoding="utf-8") as f:
        f.write(today_kst_str())

def load_news_embeddings() -> Tuple[pd.DataFrame, np.ndarray]:
    """
    PostgreSQLì—ì„œ ìµœê·¼ 24ì‹œê°„ ë‰´ìŠ¤ ë°ì´í„°ì™€ ì„ë² ë”© ë²¡í„°ë¥¼ ë¡œë“œ
    
    Returns:
        news_df: ë‰´ìŠ¤ ë©”íƒ€ë°ì´í„° DataFrame
        embeddings_matrix: ë‰´ìŠ¤ ì„ë² ë”© í–‰ë ¬ (n_news x embedding_dim)
    """
    from datetime import datetime, timedelta
    from zoneinfo import ZoneInfo
    
    db = SessionLocal()
    try:
        # 24ì‹œê°„ ì´ë‚´ ë‰´ìŠ¤ë§Œ ì¡°íšŒ (í•œêµ­ ì‹œê°„ ê¸°ì¤€)
        kst = ZoneInfo("Asia/Seoul")
        now = datetime.now(kst)
        yesterday = now - timedelta(days=1)
        
        print(f"[INFO] Loading news from {yesterday.strftime('%Y-%m-%d %H:%M')} to {now.strftime('%Y-%m-%d %H:%M')} (KST)")
        
        # ì„ë² ë”©ì´ ìˆê³  24ì‹œê°„ ì´ë‚´ ì‘ì„±ëœ ë‰´ìŠ¤ë§Œ ì¡°íšŒ
        news_query = db.query(News).filter(
            News.embedding.isnot(None),
            News.created_at >= yesterday,
            News.created_at <= now
        ).all()
        
        if not news_query:
            print("[WARNING] No recent news with embeddings found in database")
            print(f"[DEBUG] Trying to load any news with embeddings for testing...")
            
            # 24ì‹œê°„ ì œí•œ ì—†ì´ ìµœì‹  1000ê°œë§Œ ì¡°íšŒ (í…ŒìŠ¤íŠ¸ìš©)
            news_query = db.query(News).filter(
                News.embedding.isnot(None)
            ).order_by(News.created_at.desc()).limit(1000).all()
            
            if not news_query:
                print("[ERROR] No news with embeddings found at all")
                return pd.DataFrame(), np.array([])
            else:
                print(f"[INFO] Loaded latest {len(news_query)} news for testing")
        
        # ë‰´ìŠ¤ ë©”íƒ€ë°ì´í„° DataFrame ìƒì„±
        news_data = []
        embeddings = []
        
        for news in news_query:
            news_data.append({
                'news_id': news.id,
                'title': news.title,
                'category': news.category,
                'news_paper': news.news_paper,
                'created_at': news.created_at,
                'views': news.views
            })
            embeddings.append(news.embedding)
        
        news_df = pd.DataFrame(news_data)
        embeddings_matrix = np.array(embeddings)
        
        print(f"[INFO] Loaded {len(news_df)} news with embeddings")
        print(f"[INFO] Embedding dimension: {embeddings_matrix.shape[1] if len(embeddings_matrix) > 0 else 0}")
        print(f"[INFO] Date range: {news_df['created_at'].min()} ~ {news_df['created_at'].max()}")
        
        return news_df, embeddings_matrix
        
    except Exception as e:
        print(f"[ERROR] Failed to load news embeddings: {e}")
        return pd.DataFrame(), np.array([])
    finally:
        db.close()

def create_user_profiles(interactions_df: pd.DataFrame, news_df: pd.DataFrame, 
                        embeddings_matrix: np.ndarray) -> Tuple[Dict, Dict]:
    """
    ì‚¬ìš©ìë³„ í”„ë¡œí•„ ë²¡í„° ìƒì„± (ìƒí˜¸ì‘ìš©í•œ ë‰´ìŠ¤ë“¤ì˜ ê°€ì¤‘ í‰ê·  ì„ë² ë”©)
    
    Args:
        interactions_df: ì‚¬ìš©ì-ë‰´ìŠ¤ ìƒí˜¸ì‘ìš© ë°ì´í„°
        news_df: ë‰´ìŠ¤ ë©”íƒ€ë°ì´í„°
        embeddings_matrix: ë‰´ìŠ¤ ì„ë² ë”© í–‰ë ¬
        
    Returns:
        user_profiles: {user_id: profile_vector}
        user_stats: {user_id: {'total_interactions': int, 'avg_strength': float}}
    """
    if embeddings_matrix.size == 0:
        return {}, {}
    
    # ë‰´ìŠ¤ IDë¥¼ ì¸ë±ìŠ¤ë¡œ ë§¤í•‘
    news_id_to_idx = {news_id: idx for idx, news_id in enumerate(news_df['news_id'].values)}
    
    user_profiles = {}
    user_stats = {}
    
    for user_id in interactions_df['user_id'].unique():
        user_interactions = interactions_df[interactions_df['user_id'] == user_id]
        
        # í•´ë‹¹ ì‚¬ìš©ìê°€ ìƒí˜¸ì‘ìš©í•œ ë‰´ìŠ¤ë“¤ì˜ ì„ë² ë”©ê³¼ ê°•ë„
        user_embeddings = []
        user_weights = []
        
        for _, row in user_interactions.iterrows():
            news_id = row['news_id']
            strength = row['strength']
            
            if news_id in news_id_to_idx:
                idx = news_id_to_idx[news_id]
                user_embeddings.append(embeddings_matrix[idx])
                user_weights.append(strength)
        
        if user_embeddings:
            user_embeddings = np.array(user_embeddings)
            user_weights = np.array(user_weights)
            
            # ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ì‚¬ìš©ì í”„ë¡œí•„ ìƒì„±
            profile_vector = np.average(user_embeddings, axis=0, weights=user_weights)
            
            # ì •ê·œí™”
            profile_vector = normalize([profile_vector])[0]
            
            user_profiles[user_id] = profile_vector
            user_stats[user_id] = {
                'total_interactions': len(user_interactions),
                'avg_strength': user_interactions['strength'].mean(),
                'interacted_news_count': len(user_embeddings)
            }
    
    print(f"[INFO] Created profiles for {len(user_profiles)} users")
    return user_profiles, user_stats

def generate_recommendations(user_profiles: Dict, news_df: pd.DataFrame, 
                           embeddings_matrix: np.ndarray, top_k: int = 50) -> Dict:
    """
    ì‚¬ìš©ìë³„ CBF ì¶”ì²œ ìƒì„± (ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜)
    
    Args:
        user_profiles: ì‚¬ìš©ì í”„ë¡œí•„ ë²¡í„°ë“¤
        news_df: ë‰´ìŠ¤ ë©”íƒ€ë°ì´í„°
        embeddings_matrix: ë‰´ìŠ¤ ì„ë² ë”© í–‰ë ¬
        top_k: ì‚¬ìš©ìë³„ ì¶”ì²œí•  ë‰´ìŠ¤ ìˆ˜
        
    Returns:
        recommendations: {user_id: [{'news_id': int, 'score': float, 'title': str}, ...]}
    """
    if embeddings_matrix.size == 0:
        return {}
    
    recommendations = {}
    
    # ë‰´ìŠ¤ ì„ë² ë”© ì •ê·œí™” (ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° ìµœì í™”)
    normalized_embeddings = normalize(embeddings_matrix)
    
    for user_id, profile_vector in user_profiles.items():
        # ì‚¬ìš©ì í”„ë¡œí•„ê³¼ ëª¨ë“  ë‰´ìŠ¤ ê°„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        similarities = cosine_similarity([profile_vector], normalized_embeddings)[0]
        
        # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬
        similar_indices = np.argsort(-similarities)[:top_k]
        
        user_recommendations = []
        for idx in similar_indices:
            news_id = news_df.iloc[idx]['news_id']
            score = similarities[idx]
            title = news_df.iloc[idx]['title']
            category = news_df.iloc[idx]['category']
            
            user_recommendations.append({
                'news_id': int(news_id),
                'score': float(score),
                'title': title,
                'category': category
            })
        
        recommendations[user_id] = user_recommendations
    
    print(f"[INFO] Generated recommendations for {len(recommendations)} users")
    print(f"[INFO] Average recommendations per user: {top_k}")
    
    return recommendations

def save_cbf_model(recommendations: Dict, user_profiles: Dict, user_stats: Dict, 
                   news_count: int, embedding_dim: int):
    """
    CBF ëª¨ë¸ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥
    
    Args:
        recommendations: ì‚¬ìš©ìë³„ ì¶”ì²œ ê²°ê³¼
        user_profiles: ì‚¬ìš©ì í”„ë¡œí•„ ë²¡í„°ë“¤
        user_stats: ì‚¬ìš©ìë³„ í†µê³„ ì •ë³´
        news_count: ì „ì²´ ë‰´ìŠ¤ ìˆ˜
        embedding_dim: ì„ë² ë”© ì°¨ì›
    """
    # models ë””ë ‰í† ë¦¬ ìƒì„±
    MODELS_DIR.mkdir(exist_ok=True)
    
    # CBF ëª¨ë¸ ë°ì´í„° íŒ¨í‚¤ì§•
    cbf_model_data = {
        'recommendations': recommendations,
        'user_profiles': user_profiles,
        'user_stats': user_stats,
        'trained_at': datetime.now(timezone.utc),
        'train_date': today_kst_str(),
        'model_params': {
            'total_users': len(user_profiles),
            'total_news': news_count,
            'embedding_dim': embedding_dim,
            'top_k_recommendations': 50,
            'similarity_metric': 'cosine'
        }
    }
    
    # ëª¨ë¸ì„ pickle íŒŒì¼ë¡œ ì €ì¥
    with open(CBF_MODEL_PATH, 'wb') as f:
        pickle.dump(cbf_model_data, f)
    
    # ë©”íƒ€ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥ (ë””ë²„ê¹… ë° í™•ì¸ìš©)
    metadata = {
        'trained_at': cbf_model_data['trained_at'].isoformat(),
        'train_date': cbf_model_data['train_date'],
        'total_users': len(user_profiles),
        'total_news': news_count,
        'embedding_dim': embedding_dim,
        'model_file': str(CBF_MODEL_PATH.name),
        'sample_users': list(recommendations.keys())[:5] if recommendations else []
    }
    
    with open(CBF_METADATA_PATH, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, indent=2, ensure_ascii=False)
    
    print(f"[INFO] CBF model saved to {CBF_MODEL_PATH}")
    print(f"[INFO] CBF metadata saved to {CBF_METADATA_PATH}")
    print(f"[INFO] Users: {len(user_profiles)}, News: {news_count}")

def test_cbf_recommendations(recommendations: Dict, user_stats: Dict, interactions_df: pd.DataFrame, num_test_users: int = 3):
    """
    CBF ì¶”ì²œ ê²°ê³¼ í…ŒìŠ¤íŠ¸ ì¶œë ¥ (train_cf ìŠ¤íƒ€ì¼)
    
    Args:
        recommendations: ì‚¬ìš©ìë³„ ì¶”ì²œ ê²°ê³¼
        user_stats: ì‚¬ìš©ìë³„ í†µê³„ ì •ë³´
        interactions_df: ì›ë³¸ ìƒí˜¸ì‘ìš© ë°ì´í„°
        num_test_users: í…ŒìŠ¤íŠ¸í•  ì‚¬ìš©ì ìˆ˜
    """
    if not recommendations:
        print("[WARNING] No recommendations to test")
        return
    
    print(f"\n{'='*60}")
    print(f"ğŸ¯ CBF ì¶”ì²œ ê²°ê³¼ í…ŒìŠ¤íŠ¸ ({num_test_users}ëª…ì˜ ìƒ˜í”Œ ì‚¬ìš©ì)")
    print(f"{'='*60}")
    
    # ëœë¤í•˜ê²Œ ì‚¬ìš©ì ì„ íƒ
    import random
    all_users = list(recommendations.keys())
    sample_users = random.sample(all_users, min(num_test_users, len(all_users)))
    
    for idx, user_id in enumerate(sample_users, 1):
        user_recs = recommendations[user_id]
        stats = user_stats.get(user_id, {})
        
        print(f"\nğŸ“Š [{idx}] User ID: {user_id}")
        print(f"   ğŸ’¬ ì´ ìƒí˜¸ì‘ìš©: {stats.get('total_interactions', 0)}íšŒ")
        print(f"   ğŸ¯ ìƒí˜¸ì‘ìš© ë‰´ìŠ¤ ìˆ˜: {stats.get('interacted_news_count', 0)}ê°œ")
        print(f"   ğŸ“ˆ í‰ê·  ìƒí˜¸ì‘ìš© ê°•ë„: {stats.get('avg_strength', 0):.3f}")
        
        # ì‚¬ìš©ìê°€ ì‹¤ì œë¡œ ìƒí˜¸ì‘ìš©í•œ ë‰´ìŠ¤ë“¤ í‘œì‹œ
        user_interactions = interactions_df[interactions_df['user_id'] == user_id]
        if not user_interactions.empty:
            top_interactions = user_interactions.nlargest(3, 'strength')
            print(f"\n   ğŸ“– ìµœê³  ìƒí˜¸ì‘ìš© ë‰´ìŠ¤:")
            for i, (_, row) in enumerate(top_interactions.iterrows(), 1):
                print(f"      {i}. News ID {row['news_id']} (ê°•ë„: {row['strength']:.2f})")
        
        # CBF ì¶”ì²œ ê²°ê³¼
        print(f"\n   ğŸ¤– CBF ì¶”ì²œ ë‰´ìŠ¤ (ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜):")
        for i, rec in enumerate(user_recs[:5], 1):  # ìƒìœ„ 5ê°œ
            title_short = rec['title'][:45] + "..." if len(rec['title']) > 45 else rec['title']
            category_display = f"[{rec['category']}]" if rec['category'] else "[ê¸°íƒ€]"
            print(f"      {i}. {category_display} {title_short}")
            print(f"          â†’ ìœ ì‚¬ë„: {rec['score']:.4f} | News ID: {rec['news_id']}")
        
        print(f"   {'â”€'*50}")
    
    # ì „ì²´ í†µê³„
    total_users = len(recommendations)
    avg_recs_per_user = sum(len(recs) for recs in recommendations.values()) / total_users
    
    print(f"\nğŸ“ˆ CBF ëª¨ë¸ ì „ì²´ í†µê³„:")
    print(f"   â€¢ í”„ë¡œí•„ì´ ìƒì„±ëœ ì‚¬ìš©ì: {total_users:,}ëª…")
    print(f"   â€¢ ì‚¬ìš©ìë‹¹ í‰ê·  ì¶”ì²œ ìˆ˜: {avg_recs_per_user:.1f}ê°œ")
    print(f"   â€¢ ìœ ì‚¬ë„ ë²”ìœ„: {min([min([r['score'] for r in recs]) for recs in recommendations.values()]):.4f} ~ {max([max([r['score'] for r in recs]) for recs in recommendations.values()]):.4f}")
    
    # ì¹´í…Œê³ ë¦¬ë³„ ì¶”ì²œ ë¶„í¬ 
    all_categories = {}
    for recs in recommendations.values():
        for rec in recs[:10]:  # ìƒìœ„ 10ê°œë§Œ ë¶„ì„
            cat = rec['category'] or 'ê¸°íƒ€'
            all_categories[cat] = all_categories.get(cat, 0) + 1
    
    print(f"\nğŸ“Š ì¶”ì²œ ì¹´í…Œê³ ë¦¬ ë¶„í¬ (ìƒìœ„ 5ê°œ):")
    top_categories = sorted(all_categories.items(), key=lambda x: x[1], reverse=True)[:5]
    for cat, count in top_categories:
        percentage = (count / sum(all_categories.values())) * 100
        print(f"   â€¢ {cat}: {count:,}íšŒ ({percentage:.1f}%)")
    
    print(f"\nâœ… CBF ì¶”ì²œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

def main():
    """
    CBF ì¶”ì²œ ëª¨ë¸ í•™ìŠµ ë° ì €ì¥ ë©”ì¸ í•¨ìˆ˜
    
    1. ì˜¤ëŠ˜ ì´ë¯¸ CBF í•™ìŠµì„ ì™„ë£Œí–ˆëŠ”ì§€ í™•ì¸
    2. BigQueryì—ì„œ ì‚¬ìš©ì ìƒí˜¸ì‘ìš© ë°ì´í„° ë¡œë“œ
    3. PostgreSQLì—ì„œ ë‰´ìŠ¤ ì„ë² ë”© ë°ì´í„° ë¡œë“œ
    4. ì‚¬ìš©ìë³„ í”„ë¡œí•„ ë²¡í„° ìƒì„±
    5. ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜ CBF ì¶”ì²œ ìƒì„±
    6. ëª¨ë¸ ê²°ê³¼ë¥¼ íŒŒì¼ ì‹œìŠ¤í…œì— ì €ì¥
    """
    print(f"[START] CBF ëª¨ë¸ í•™ìŠµ ì‹œì‘ - {datetime.now()}")
    
    # 1. ì´ë¯¸ ì˜¤ëŠ˜ CBF í•™ìŠµì„ ì™„ë£Œí–ˆëŠ”ì§€ í™•ì¸
    if already_trained_cbf_today():
        print("[SKIP] CBF model already trained today.")
        return
    
    # 2. BigQueryì—ì„œ ì‚¬ìš©ì ìƒí˜¸ì‘ìš© ë°ì´í„° ë¡œë“œ (CFì™€ ë™ì¼í•œ ë°ì´í„° ì‚¬ìš©)
    try:
        client = get_client()
        interactions_df = fetch_interactions(client)
        print(f"[INFO] Loaded {len(interactions_df)} user interactions")
        
        if interactions_df.empty:
            print("[SKIP] No interaction data available for CBF training")
            return
            
    except Exception as e:
        print(f"[ERROR] Failed to load interaction data: {e}")
        return
    
    # 3. PostgreSQLì—ì„œ ë‰´ìŠ¤ ì„ë² ë”© ë°ì´í„° ë¡œë“œ
    news_df, embeddings_matrix = load_news_embeddings()
    
    if news_df.empty or embeddings_matrix.size == 0:
        print("[SKIP] No news embeddings available for CBF training")
        return
    
    # 4. ì‚¬ìš©ìë³„ í”„ë¡œí•„ ë²¡í„° ìƒì„±
    user_profiles, user_stats = create_user_profiles(interactions_df, news_df, embeddings_matrix)
    
    if not user_profiles:
        print("[SKIP] No user profiles created for CBF training")
        return
    
    # 5. CBF ì¶”ì²œ ìƒì„±
    recommendations = generate_recommendations(user_profiles, news_df, embeddings_matrix, top_k=50)
    
    if not recommendations:
        print("[SKIP] No recommendations generated")
        return
    
    # 6. CBF ëª¨ë¸ ì €ì¥
    save_cbf_model(recommendations, user_profiles, user_stats, 
                   len(news_df), embeddings_matrix.shape[1])
    
    # 7. í…ŒìŠ¤íŠ¸ìš© ì¶”ì²œ ê²°ê³¼ ì¶œë ¥ (train_cf ìŠ¤íƒ€ì¼)
    test_cbf_recommendations(recommendations, user_stats, interactions_df, num_test_users=3)
    
    # 8. ì˜¤ëŠ˜ CBF í•™ìŠµ ì™„ë£Œ ìƒíƒœ ê¸°ë¡
    mark_cbf_trained_today()
    
    print(f"[SUCCESS] CBF ëª¨ë¸ í•™ìŠµ ì™„ë£Œ - {datetime.now()}")

if __name__ == "__main__":
    main()